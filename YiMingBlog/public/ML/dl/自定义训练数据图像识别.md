---
layout: doc
title: 自定义训练数据图像识别
tags:
  - "#博文"
  - "#以撒"
  - "#深度学习"
  - "#图像识别"
datetime: 2024-01-23
time: 14:37
description: 
navbar: true
sidebar: true
footer: true
---

# 引言
![[3.png]]
最近在玩以撒的结合, ns版本. 游戏确实上头好玩, 内容很多. 但是游玩下来遇到一个纠结头疼的问题就是, 道具/ 装备 有时候捡起来后的效果, 还不如不捡.   
装备/道具只会在捡起来的时候才能看到道具和状态是什么, 甚至, 有时候捡起来后描述也看不出这个道具到底能用来干嘛,  魂系叙事那一套......虽然也找到不错的[以撒wiki]([以撒的结合中文维基 - 灰机wiki - 北京嘉闻杰诺网络科技有限公司 (huijiwiki.com)](https://isaac.huijiwiki.com/wiki/%E9%A6%96%E9%A1%B5)), 但是, 站点只能文字搜索, 再加上其道具数量有7百多个, 叠加起来就更让人头疼了. 
![[以撒自定义训练数据图像识别-2024-01-23.png]]

于是就想到, 干脆做一个“以撒道具图像识别功能” 好了, 优化体验: ) .   

# 自定义训练数据图像识别

得益于各种深度学习框架的发展, 现在训练一个模型变得非常简单, 于是我就决定直接用`pytorch`来完成这个图片识别的任务了.  考虑到以撒的道具装备这类东西图像数据是非常**垂直领域**了, 所以我需要准备对应的训练数据进行模型的训练.  

## 数据准备  

### 数据获取  
从[以撒的结合中文维基](https://isaac.huijiwiki.com/wiki/%E9%A6%96%E9%A1%B5) 编写爬虫把道具/装备的图片数据, 描述都抓取下来.  
爬虫比较简单, 主要就是图片爬取的时候, 需要从css中把sprite图子图的x, y提取出来, 然后自行使用sprite划分独立的道具图. 下图为css和html标签中抽取出来的信息
```python
{'collectibles_001': {'x': 32,
  'y': 0,
  'en': 'The Sad Onion',
  'zh': '悲伤洋葱',
  'level': '1',
  'type': '道具',
  'level2': '3',
  '?': '/',
  'desc': '射速上升。',
  'new_id': 0,
  'image': './cus_data/0.png'}, ...
} # 提取出每个道具的图片和其他属性
```

然后把图片分割后某个目录, 此处我是把裁切好的图片存放在 `./cus_data`下. 并且把图片. 整理后得到训练的类别标签备用.
```python
>>>classes
{0: '悲伤洋葱:射速上升。',
 1: '内眼:角色每次发射3颗泪弹。',
 2: '弯勺魔术:角色的泪弹获得追踪效果。',
 3: '柯吉猫的头:泪弹变大，击退效果上升，伤害上升。',
 4: '我的镜像:角色的泪弹会飞回角色身边。',
 5: '小号:射程下降，射速上升。',
 ...
```

此处我把图片缩放成64 * 64 的格式后保存, 模拟真实使用相机拍摄后扣取的大小范围.
![[自定义训练数据图像识别-2024-01-24.png]]
### 数据合成  


### 自定义训练数据  
导入pytorch的运行环境,  编写自定义的dataset 和 dataloader
```python
import torch
from torch import nn
device = (
    "cuda"
    if torch.cuda.is_available()
    else "mps"
    if torch.backends.mps.is_available()
    else "cpu"
)
print(f"Using {device} device")


transform = transforms.Compose([
     # 增加噪声, 防止过拟合, 模拟现实照片拍摄截取后的模糊   
     transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),  # 抖动图像的亮度、对比度、饱和度和色相
     transforms.Lambda(lambda x: x.float()),  # 转化格式为float
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 图片正则化

batch_size = 4
labels = list(range(len(os.listdir("cus_data"))))
train_dataset = IssacCustomDatasets(labels, img_dir="cus_data/",
                                    transform=transform)
                                    
## dataloader
train_dataloader = DataLoader(train_dataset, 
                              batch_size=batch_size, 
                              shuffle=True)
# test_loader = train_dataloader
```

### 小批量训练模型  
因为图片识别任务输入的图片比较简单, 所以我这儿直接用vgg16来训练一个小模型就可以了. 考虑到原版的vgg16是基于244x244的ImageNet的图片输入, 此处我还需要调整一下他最后池化层的7x7的特征图的输入, 还有最后的全连接层的输出.
```python
from matplotlib import pyplot as plt
from torchvision.models import vgg16

net = vgg16(num_classes=len(classes))
net.to(device)  # 移动到 device

criterion = nn.CrossEntropyLoss()
# optimizer = optim.SGD(net.parameters(), lr=0.00001, momentum=0.9)
optimizer = optim.Adam(net.parameters(), lr=0.00001)

# 训练模型
loss_batch = 4
train_epoch = 20
for epoch in range(train_epoch):
    net.train()  # 每个epoch 后切换训练模式
    running_loss = 0.0
    for i, data in enumerate(train_dataloader, 0):
        inputs, labels = data  # 必须要float 归一化? 浮点类型.
        inputs, labels = inputs.float().to(device), labels.to(device)
        optimizer.zero_grad()

        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
        if i % loss_batch == 0:    # 每 4 个小批量打印一次损失值
            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / loss_batch))
            running_loss = 0.0
            
    if epoch % 4 == 1:  # 每4个epoch进行一次验证
        net.eval()
        with torch.no_grad():
            for i, data in enumerate(train_dataloader, 0):
                if i >= 20:
                    break
                inputs, labels = data
                inputs = inputs.float().to(device)
                outputs = net(inputs)
                _, predicted = torch.max(outputs.data, 1)
                print('Real: ', labels, ', Predicted: ', predicted)
    print(f"---------{epoch} -------epoch")
    print()
    
print('Finished Training')
```

大批量训练数据



